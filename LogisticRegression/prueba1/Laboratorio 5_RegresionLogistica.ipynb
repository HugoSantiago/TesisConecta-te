{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará el conjunto de datos Breast Cancer, relacionado con el diagnóstico de cancer de pecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datos\n",
    "#from sklearn.datasets import load_breast_cancer\n",
    "#breast = load_breast_cancer()\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploración de los datos\n",
    "reg = linear_model.LogisticRegression()\n",
    "\n",
    "df = pd.read_csv(\"Documentsporcentajes.csv\")\n",
    "\n",
    "lstx = df[df.columns[:-6]].to_numpy()\n",
    "lsty = df[df.columns[-1]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fail', 'Fail', 'Pass', ..., 'Pass', 'Fail', 'Fail'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se construye el dataframe. Se separan datos de entrada y datos de salida\n",
    "#feature_names = breast['feature_names']\n",
    "#breast_data = pd.DataFrame(breast['data'],columns = [feature_names])\n",
    "#breast_target = pd.DataFrame(breast['target'], columns = ['Class'])\n",
    "#breast_dataset = pd.concat([breast_data, breast_target], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#breast_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(mean radius,)</th>\n",
       "      <th>(mean texture,)</th>\n",
       "      <th>(mean perimeter,)</th>\n",
       "      <th>(mean area,)</th>\n",
       "      <th>(mean smoothness,)</th>\n",
       "      <th>(mean compactness,)</th>\n",
       "      <th>(mean concavity,)</th>\n",
       "      <th>(mean concave points,)</th>\n",
       "      <th>(mean symmetry,)</th>\n",
       "      <th>(mean fractal dimension,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(worst texture,)</th>\n",
       "      <th>(worst perimeter,)</th>\n",
       "      <th>(worst area,)</th>\n",
       "      <th>(worst smoothness,)</th>\n",
       "      <th>(worst compactness,)</th>\n",
       "      <th>(worst concavity,)</th>\n",
       "      <th>(worst concave points,)</th>\n",
       "      <th>(worst symmetry,)</th>\n",
       "      <th>(worst fractal dimension,)</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (mean radius,)  (mean texture,)  (mean perimeter,)  (mean area,)  \\\n",
       "0           17.99            10.38             122.80        1001.0   \n",
       "1           20.57            17.77             132.90        1326.0   \n",
       "2           19.69            21.25             130.00        1203.0   \n",
       "3           11.42            20.38              77.58         386.1   \n",
       "4           20.29            14.34             135.10        1297.0   \n",
       "\n",
       "   (mean smoothness,)  (mean compactness,)  (mean concavity,)  \\\n",
       "0             0.11840              0.27760             0.3001   \n",
       "1             0.08474              0.07864             0.0869   \n",
       "2             0.10960              0.15990             0.1974   \n",
       "3             0.14250              0.28390             0.2414   \n",
       "4             0.10030              0.13280             0.1980   \n",
       "\n",
       "   (mean concave points,)  (mean symmetry,)  (mean fractal dimension,)  ...  \\\n",
       "0                 0.14710            0.2419                    0.07871  ...   \n",
       "1                 0.07017            0.1812                    0.05667  ...   \n",
       "2                 0.12790            0.2069                    0.05999  ...   \n",
       "3                 0.10520            0.2597                    0.09744  ...   \n",
       "4                 0.10430            0.1809                    0.05883  ...   \n",
       "\n",
       "   (worst texture,)  (worst perimeter,)  (worst area,)  (worst smoothness,)  \\\n",
       "0             17.33              184.60         2019.0               0.1622   \n",
       "1             23.41              158.80         1956.0               0.1238   \n",
       "2             25.53              152.50         1709.0               0.1444   \n",
       "3             26.50               98.87          567.7               0.2098   \n",
       "4             16.67              152.20         1575.0               0.1374   \n",
       "\n",
       "   (worst compactness,)  (worst concavity,)  (worst concave points,)  \\\n",
       "0                0.6656              0.7119                   0.2654   \n",
       "1                0.1866              0.2416                   0.1860   \n",
       "2                0.4245              0.4504                   0.2430   \n",
       "3                0.8663              0.6869                   0.2575   \n",
       "4                0.2050              0.4000                   0.1625   \n",
       "\n",
       "   (worst symmetry,)  (worst fractal dimension,)  Class  \n",
       "0             0.4601                     0.11890      0  \n",
       "1             0.2750                     0.08902      0  \n",
       "2             0.3613                     0.08758      0  \n",
       "3             0.6638                     0.17300      0  \n",
       "4             0.2364                     0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se visualizan las primeras filas de datos\n",
    "#breast_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estas primeras pruebas no se escalarán las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la estimación del modelo con regresión logística\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se preparan los datos para realizar la construcción del modelo. \n",
    "#X = breast['data']\n",
    "#y = breast['target']\n",
    "\n",
    "x_train , x_test, y_train, y_test = train_test_split(lstx, lsty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ejemplo con solo entrenamiento y test, sin regularización ni ajuste de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division entre entrenamiento y test\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea el modelo. Siguiendo las recomendacioens de la documentación, como la muestra es pequeña, se utilizará el método \n",
    "# de optimización liblinear el cual de basa en descenso por el gradiente.\n",
    "logreg = LogisticRegression(solver = 'liblinear', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se entrena el modelo\n",
    "logreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo sobre el conjunto de entrenamiento: 0.628\n",
      "Exactitud del modelo sobre el conjunto test: 0.627\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "print(\"Exactitud del modelo sobre el conjunto de entrenamiento: {:.3f}\".format(logreg.score(x_train, y_train)))\n",
    "print(\"Exactitud del modelo sobre el conjunto test: {:.3f}\". format(logreg.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para sacar la matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión logistica\n",
      " [[49  4]\n",
      " [ 5 85]]\n"
     ]
    }
   ],
   "source": [
    "logreg_predicted = logreg.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, logreg_predicted)\n",
    "print('Regresión logistica\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg_predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5fc7df50d92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Para mostrar un reporte con un conjunto de métricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg_predicted' is not defined"
     ]
    }
   ],
   "source": [
    "#Para mostrar un reporte con un conjunto de métricas\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, logreg_predicted, target_names = lsty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Ahora se utilizará regularización L2 (definida por defecto). Se debe entonces buscar el valor del hiperparámetro de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor parámetro: {'C': 100}\n",
      "Mejor cross-validation score: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=10, random_state = 0)\n",
    "logreg = LogisticRegression(solver = 'liblinear', random_state = 0)\n",
    "parametros = {'C': [0.001, 0.01, 0.05, 0.1, 1.0, 10, 100]}\n",
    "mejor_modelo = GridSearchCV(logreg,param_grid =parametros, cv=kf)\n",
    "mejor_modelo.fit(x_train, y_train) \n",
    "\n",
    "print(\"Mejor parámetro: {}\".format(mejor_modelo.best_params_)) \n",
    "print(\"Mejor cross-validation score: {:.2f}\".format(mejor_modelo.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Error sobre el conjunto test\n",
    "print(\"Test set score: {:.2f}\".format(mejor_modelo.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Los resultados cambiarían si se escalan o normalizan los datos?\n",
    "¿Qué resultado se obtendría si se utiliza regularización L1? \n",
    "¿Cómo visualizar la importancia de las variables a través del valor de los coeficientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
